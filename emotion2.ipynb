{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "emotion2.ipynb",
      "authorship_tag": "ABX9TyODJ4YNeql13GvkygLfzVH0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prueba2001/primera-AI/blob/main/emotion2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Montar tu Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2️⃣ Definir la ruta del archivo ZIP en tu Drive\n",
        "# ⚠️ Ajusta la ruta según la ubicación exacta del archivo en tu Drive\n",
        "zip_path = '/content/drive/MyDrive/dataset_mel.zip'\n",
        "\n",
        "# 3️⃣ Definir la carpeta donde quieres descomprimirlo\n",
        "extract_path = '/content/dataset'\n",
        "\n",
        "# 4️⃣ Descomprimir el archivo\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Crear la carpeta destino si no existe\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extraer el contenido\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"✅ Archivo descomprimido en: {extract_path}\")"
      ],
      "metadata": {
        "id": "coVvw6BWu8ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready: Fine-tune ResNet-101 on an ImageFolder dataset (no Drive saving)\n",
        "# -------------------------------------------------------------------------\n",
        "# Nota: si ves el error relacionado con PIL._typing, este script fuerza\n",
        "# Pillow==9.5.0 antes de importar torchvision para evitar ese ImportError.\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "# ------------------ 0) Instalar dependencias (ejecutar solo si es necesario) ------------------\n",
        "# (Pillow se fija en 9.5.0 para evitar ImportError con PIL._typing)\n",
        "!pip install -q --upgrade \"tqdm\" \"scikit-learn\" \"matplotlib\" \"Pillow==9.5.0\"\n",
        "\n",
        "# Si quieres forzar también torch/torchvision (opcional y pesado):\n",
        "# !pip install -q --upgrade \"torch\" \"torchvision\"\n",
        "\n",
        "# ------------------ 1) Imports (intenta importar; si falla reinstala Pillow y reintenta) ------------------\n",
        "import sys, subprocess, importlib\n",
        "\n",
        "def try_imports():\n",
        "    try:\n",
        "        import os, time, copy, json\n",
        "        from pathlib import Path\n",
        "        from collections import Counter\n",
        "        import torch\n",
        "        import torch.nn as nn\n",
        "        from torch.utils.data import DataLoader\n",
        "        from torchvision import transforms, datasets, models\n",
        "        from tqdm import tqdm\n",
        "        import numpy as np\n",
        "        from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "        import matplotlib.pyplot as plt\n",
        "        from PIL import Image\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"Import error:\", e)\n",
        "        return False\n",
        "\n",
        "if not try_imports():\n",
        "    print(\"Reinstalando Pillow==9.5.0 y reintentando imports...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", \"--force-reinstall\", \"Pillow==9.5.0\"])\n",
        "    importlib.invalidate_caches()\n",
        "    if not try_imports():\n",
        "        raise RuntimeError(\n",
        "            \"Error importando dependencias aún después de reinstalar Pillow. \"\n",
        "            \"En Colab reinicia el runtime (Runtime -> Restart runtime) y vuelve a ejecutar la celda.\"\n",
        "        )\n",
        "\n",
        "# Ahora los imports definitivos (si llegaste hasta aquí, deberían funcionar)\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------ 2) Config (editar si quieres) ------------------\n",
        "DATA_ROOT = '/content/dataset'  # mantener como dijiste\n",
        "TRAIN_DIR = os.path.join(DATA_ROOT, 'train')\n",
        "VAL_DIR   = os.path.join(DATA_ROOT, 'val')\n",
        "TEST_DIR  = os.path.join(DATA_ROOT, 'test')\n",
        "\n",
        "# <-- Salida local en /content para no usar Drive -->\n",
        "OUTPUT_DIR = '/content/finetune_resnet101_output'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "NUM_EPOCHS = 8\n",
        "BATCH_SIZE = 16            # si OOM, bajar a 8 o 4\n",
        "IMG_SIZE = 224\n",
        "LR = 1e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_WORKERS = 2            # 2 es más seguro en Colab\n",
        "PIN_MEMORY = True\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "PRINT_FREQ = 1\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ------------------ 3) Transforms ------------------\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ------------------ 4) Datasets & Loaders ------------------\n",
        "# Verifica que las rutas existan\n",
        "for d in (TRAIN_DIR, VAL_DIR, TEST_DIR):\n",
        "    if not os.path.isdir(d):\n",
        "        raise FileNotFoundError(f\"Directorio no encontrado: {d}. Asegúrate de tener /content/dataset/{{train,val,test}} con subcarpetas por clase.\")\n",
        "\n",
        "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(VAL_DIR, transform=val_transforms)\n",
        "test_dataset  = datasets.ImageFolder(TEST_DIR, transform=val_transforms)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "num_classes = len(class_names)\n",
        "print(f\"Detected classes ({num_classes}): {class_names}\")\n",
        "\n",
        "# Compute class weights (para imbalance)\n",
        "counts = Counter([y for _, y in train_dataset])\n",
        "class_counts = [counts[i] for i in range(num_classes)]\n",
        "print('Train class counts:', dict(zip(class_names, class_counts)))\n",
        "\n",
        "# Evitar división por cero: si una clase tiene 0 muestras, le damos peso 0.\n",
        "if sum(class_counts) == 0:\n",
        "    raise ValueError(\"No hay imágenes en el dataset de entrenamiento.\")\n",
        "class_weights = []\n",
        "total = float(sum(class_counts))\n",
        "for c in class_counts:\n",
        "    if c > 0:\n",
        "        class_weights.append(total / c)\n",
        "    else:\n",
        "        class_weights.append(0.0)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "# normalizar (opcional)\n",
        "if class_weights.sum().item() > 0:\n",
        "    class_weights = class_weights / class_weights.sum() * num_classes\n",
        "class_weights = class_weights.to(DEVICE)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY if torch.cuda.is_available() else False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY if torch.cuda.is_available() else False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                         num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY if torch.cuda.is_available() else False)\n",
        "\n",
        "# ------------------ 5) Modelo ------------------\n",
        "# Usar la API de pesos recomendada\n",
        "try:\n",
        "    from torchvision.models import ResNet101_Weights\n",
        "    weights = ResNet101_Weights.IMAGENET1K_V1\n",
        "    model = models.resnet101(weights=weights)\n",
        "except Exception:\n",
        "    # fallback si la versión de torchvision no expone ResNet101_Weights\n",
        "    model = models.resnet101(pretrained=True)\n",
        "\n",
        "# Reemplazar la capa final\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# ------------------ 6) Loss, optimizador, scheduler ------------------\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "# Mixed precision si hay CUDA\n",
        "use_amp = torch.cuda.is_available()\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "# ------------------ 7) Utilidades ------------------\n",
        "def save_checkpoint(state, filename):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc='Eval', leave=False):\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    epoch_loss = running_loss / len(loader.dataset) if len(loader.dataset) > 0 else 0.0\n",
        "    return np.array(all_labels), np.array(all_preds), epoch_loss\n",
        "\n",
        "# ------------------ 8) Loop de entrenamiento ------------------\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_f1 = 0.0\n",
        "history = {'train_loss': [], 'val_loss': [], 'val_f1': [], 'val_acc': []}\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{NUM_EPOCHS}')\n",
        "    for images, labels in pbar:\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        processed = min((pbar.n+1) * train_loader.batch_size, max(1, len(train_loader.dataset)))\n",
        "        pbar.set_postfix({'loss': f'{running_loss / processed:.4f}'})\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_loader.dataset) if len(train_loader.dataset) > 0 else 0.0\n",
        "    history['train_loss'].append(epoch_train_loss)\n",
        "\n",
        "    # Validación\n",
        "    y_true, y_pred, val_loss = evaluate(model, val_loader)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
        "    acc = (y_true == y_pred).mean() if y_true.size > 0 else 0.0\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_f1'].append(f1)\n",
        "    history['val_acc'].append(acc)\n",
        "\n",
        "    print(f\"Epoch {epoch} Train loss: {epoch_train_loss:.4f} | Val loss: {val_loss:.4f} | Val acc: {acc:.4f} | Val macro-F1: {f1:.4f}\")\n",
        "\n",
        "    # Scheduler con la métrica f1\n",
        "    scheduler.step(f1)\n",
        "\n",
        "    # Guardar mejor\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        ckpt_path = os.path.join(OUTPUT_DIR, f'resnet101_best_f1_{best_f1:.4f}.pth')\n",
        "        save_checkpoint({'epoch': epoch, 'model_state': best_model_wts, 'optimizer_state': optimizer.state_dict(), 'f1': best_f1}, ckpt_path)\n",
        "        print('Saved best model to', ckpt_path)\n",
        "\n",
        "# Cargar mejores pesos\n",
        "model.load_state_dict(best_model_wts)\n",
        "\n",
        "# Guardar modelo final y el historial (local)\n",
        "torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'resnet101_final.pth'))\n",
        "with open(os.path.join(OUTPUT_DIR, 'training_history.json'), 'w') as f:\n",
        "    json.dump(history, f)\n",
        "\n",
        "# ------------------ 9) Evaluación en test ------------------\n",
        "print('\\nEvaluating on test set...')\n",
        "y_true, y_pred, test_loss = evaluate(model, test_loader)\n",
        "test_acc = (y_true == y_pred).mean() if y_true.size>0 else 0.0\n",
        "print(f'Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}')\n",
        "\n",
        "# Reporte por clase\n",
        "report = classification_report(y_true, y_pred, target_names=class_names, zero_division=0)\n",
        "print('\\nClassification report:\\n')\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred) if y_true.size>0 else np.zeros((num_classes, num_classes), dtype=int)\n",
        "print('\\nConfusion matrix:\\n')\n",
        "print(cm)\n",
        "\n",
        "# Guardar report y cm (local)\n",
        "with open(os.path.join(OUTPUT_DIR, 'classification_report.txt'), 'w') as f:\n",
        "    f.write(report)\n",
        "np.savetxt(os.path.join(OUTPUT_DIR, 'confusion_matrix.csv'), cm, fmt='%d', delimiter=',')\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cm, interpolation='nearest')\n",
        "plt.title('Confusion matrix')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(num_classes), class_names, rotation=45, ha='right')\n",
        "plt.yticks(range(num_classes), class_names)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'))\n",
        "plt.show()\n",
        "\n",
        "print('\\nAll outputs saved to (local):', OUTPUT_DIR)\n",
        "\n",
        "# ------------- FIN -------------\n",
        "# Consejos si tienes OOM: reducir BATCH_SIZE a 8 o 4, o congelar capas iniciales:\n",
        "# for name, param in model.named_parameters():\n",
        "#     if 'layer4' not in name and 'fc' not in name:\n",
        "#         param.requires_grad = False"
      ],
      "metadata": {
        "id": "YznsWhtou8ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready: Inference single image(s) with ResNet-101 trained model\n",
        "# Pegar y ejecutar EN UNA SOLA CELDA en Google Colab.\n",
        "# Sube las imágenes cuando te lo pida la interfaz.\n",
        "\n",
        "# ------------------ 0) Asegurar dependencias ------------------\n",
        "# Forzamos una versión estable de Pillow para evitar el error \"cannot import name '_Ink'\".\n",
        "# Instalamos matplotlib también. Si torch/torchvision ya están instalados en tu runtime de Colab,\n",
        "# dejaremos comentada la línea para instalarlos (descomentar si necesitas reinstalarlos).\n",
        "import sys\n",
        "print(\"Comprobando / instalando dependencias (puede tardar algunos segundos)...\")\n",
        "\n",
        "# Instalar/forzar Pillow estable\n",
        "!pip install -q --upgrade \"Pillow==9.5.0\" matplotlib\n",
        "\n",
        "# Si necesitas reinstalar torch/torchvision en Colab (ejecuta solo si hace falta):\n",
        "# En muchos runtimes de Colab, torch y torchvision ya vienen instalados y optimizados.\n",
        "# !pip install -q --upgrade torch torchvision\n",
        "\n",
        "print(\"Dependencias instaladas/actualizadas. Si el runtime se reinicia, re-ejecuta la celda completa.\")\n",
        "\n",
        "# Si tras actualizar Pillow, la importación sigue fallando, reiniciaremos el runtime automáticamente.\n",
        "# (Reinicio forzado en Colab: os.kill -> el runtime se reiniciará; vuelve a ejecutar la celda completa después).\n",
        "try:\n",
        "    from PIL import Image\n",
        "except Exception as e:\n",
        "    import os, time\n",
        "    print(\"ImportError al importar PIL tras instalar Pillow. Forzando reinicio del runtime para aplicar cambios...\")\n",
        "    print(\"Error:\", e)\n",
        "    # Forzar reinicio del runtime (Colab). El usuario debe volver a ejecutar la celda después del reinicio.\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "# ------------------ 1) Imports ------------------\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, models\n",
        "from google.colab import files\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ------------------ 2) Config (editar si quieres) ------------------\n",
        "MODEL_PATH = '/content/resnet101_final.pth'  # ruta por defecto al modelo que guardaste localmente\n",
        "DATASET_TRAIN_DIR = '/content/dataset/train'  # se usa como fallback para obtener class names\n",
        "IMG_SIZE = 224\n",
        "TOPK = 5\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"Device:\", DEVICE)\n",
        "print(\"Model path:\", MODEL_PATH)\n",
        "\n",
        "# ------------------ 3) Helper: cargar state_dict robustamente ------------------\n",
        "def load_checkpoint_state_dict(path, map_location='cpu'):\n",
        "    ckpt = torch.load(path, map_location=map_location)\n",
        "    # si guardaste un dict con 'model_state' o 'model_state_dict' o 'state_dict'\n",
        "    if isinstance(ckpt, dict):\n",
        "        for key in ('model_state', 'model_state_dict', 'state_dict', 'model'):\n",
        "            if key in ckpt:\n",
        "                sd = ckpt[key]\n",
        "                return sd\n",
        "    # si es directamente state_dict\n",
        "    if isinstance(ckpt, OrderedDict) or isinstance(ckpt, dict):\n",
        "        return ckpt\n",
        "    # si fue guardado como modelo completo (rare), intentar extraer state_dict\n",
        "    if hasattr(ckpt, 'state_dict'):\n",
        "        return ckpt.state_dict()\n",
        "    raise RuntimeError(\"Formato de checkpoint no reconocido.\")\n",
        "\n",
        "def clean_state_dict(sd):\n",
        "    # remover prefijo 'module.' si existe (para modelos entrenados con DataParallel)\n",
        "    new_sd = OrderedDict()\n",
        "    for k, v in sd.items():\n",
        "        nk = k\n",
        "        if k.startswith('module.'):\n",
        "            nk = k[len('module.'):]\n",
        "        new_sd[nk] = v\n",
        "    return new_sd\n",
        "\n",
        "# ------------------ 4) Asegurar que el checkpoint existe (si no, pedir subida) ------------------\n",
        "if not os.path.isfile(MODEL_PATH):\n",
        "    print(f\"No se encuentra el modelo en {MODEL_PATH}. Por favor, sube el archivo .pth desde tu ordenador.\")\n",
        "    print(\"Selecciona el archivo .pth (por ejemplo resnet101_final.pth) en la ventana de upload.\")\n",
        "    uploaded_model = files.upload()\n",
        "    if len(uploaded_model) == 0:\n",
        "        raise FileNotFoundError(\"No se subió ningún modelo. Deteniendo ejecución.\")\n",
        "    else:\n",
        "        # Tomar el primer archivo subido como modelo\n",
        "        first_model = list(uploaded_model.keys())[0]\n",
        "        MODEL_PATH = os.path.join('/content', first_model)\n",
        "        print(\"Modelo subido y ubicado en:\", MODEL_PATH)\n",
        "\n",
        "# ------------------ 5) Cargar state_dict y construir modelo compatible ------------------\n",
        "print(\"Cargando checkpoint desde:\", MODEL_PATH)\n",
        "raw_sd = load_checkpoint_state_dict(MODEL_PATH, map_location=DEVICE)\n",
        "sd = clean_state_dict(raw_sd)\n",
        "\n",
        "# determinar num_classes a partir de la forma de fc.weight en el state_dict\n",
        "if 'fc.weight' in sd:\n",
        "    num_classes = sd['fc.weight'].shape[0]\n",
        "else:\n",
        "    # fallback: intentar deducir por otras claves\n",
        "    fc_keys = [k for k in sd.keys() if k.endswith('fc.weight') or k.endswith('.fc.weight')]\n",
        "    if len(fc_keys) > 0:\n",
        "        num_classes = sd[fc_keys[0]].shape[0]\n",
        "    else:\n",
        "        raise RuntimeError(\"No pude deducir num_classes desde el state_dict. Asegúrate de que el checkpoint contiene 'fc.weight'.\")\n",
        "\n",
        "# crear modelo (sin descargar pesos externos)\n",
        "# Nota: en versiones recientes de torchvision la API acepta weights=None\n",
        "model = models.resnet101(weights=None)\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# Intentar cargar pesos; si falla por discrepancias, intentar con strict=False y avisar.\n",
        "try:\n",
        "    model.load_state_dict(sd)\n",
        "    print(\"Pesos cargados con strict=True.\")\n",
        "except Exception as e:\n",
        "    print(\"Carga con strict=True falló:\", e)\n",
        "    print(\"Intentando cargar con strict=False (ignorar keys faltantes/excedentes).\")\n",
        "    load_res = model.load_state_dict(sd, strict=False)\n",
        "    print(\"Resultado carga strict=False:\", load_res)\n",
        "\n",
        "model.eval()\n",
        "print(f\"Modelo ResNet-101 listo. num_classes = {num_classes}\")\n",
        "\n",
        "# ------------------ 6) Obtener nombres de clase (intentos automáticos) ------------------\n",
        "CLASS_NAMES = None\n",
        "\n",
        "# 1) buscar archivo class_names.json en mismo folder del modelo\n",
        "possible_json = os.path.join(os.path.dirname(MODEL_PATH), 'class_names.json')\n",
        "if os.path.isfile(possible_json):\n",
        "    try:\n",
        "        with open(possible_json, 'r') as f:\n",
        "            CLASS_NAMES = json.load(f)\n",
        "        print(\"Cargadas class names desde\", possible_json)\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo leer class_names.json:\", e)\n",
        "\n",
        "# 2) fallback: listar carpetas en /content/dataset/train\n",
        "if CLASS_NAMES is None and os.path.isdir(DATASET_TRAIN_DIR):\n",
        "    classes = sorted([d.name for d in Path(DATASET_TRAIN_DIR).iterdir() if d.is_dir()])\n",
        "    if len(classes) == num_classes:\n",
        "        CLASS_NAMES = classes\n",
        "        print(\"Cargadas class names desde el directorio de train:\", DATASET_TRAIN_DIR)\n",
        "    else:\n",
        "        print(f\"Encontradas {len(classes)} carpetas en {DATASET_TRAIN_DIR} (esperado {num_classes}). No se usarán como class names automáticas.\")\n",
        "\n",
        "# 3) último recurso: nombres genéricos\n",
        "if CLASS_NAMES is None:\n",
        "    CLASS_NAMES = [f\"class_{i}\" for i in range(num_classes)]\n",
        "    print(\"No se encontraron nombres de clase en disco. Usando nombres genéricos class_0..\")\n",
        "\n",
        "# ------------------ 7) Transforms de entrada (mismo que validación/entrenamiento) ------------------\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ------------------ 8) Subir imagen(es) desde la UI de Colab ------------------\n",
        "print(\"\\nSelecciona 1 o más imagenes desde la ventana emergente (Upload).\")\n",
        "uploaded = files.upload()  # abre selector; carga archivos a /content\n",
        "\n",
        "if len(uploaded) == 0:\n",
        "    print(\"No se subió ninguna imagen. Termina la ejecución.\")\n",
        "else:\n",
        "    for filename in uploaded.keys():\n",
        "        img_path = os.path.join('/content', filename)\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"No pude abrir {filename}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Preprocesar\n",
        "        input_tensor = preprocess(img).unsqueeze(0).to(DEVICE)  # shape (1,C,H,W)\n",
        "\n",
        "        # Inferencia\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_tensor)\n",
        "            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        # Top-K\n",
        "        topk_idx = probs.argsort()[::-1][:TOPK]\n",
        "        topk_probs = probs[topk_idx]\n",
        "        topk_names = [CLASS_NAMES[i] if i < len(CLASS_NAMES) else f\"class_{i}\" for i in topk_idx]\n",
        "\n",
        "        # Mostrar imagen + predicción principal\n",
        "        top_name = topk_names[0]\n",
        "        top_prob = topk_probs[0]\n",
        "\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Predicción: {top_name} ({top_prob*100:.2f}%)\", fontsize=14)\n",
        "        plt.show()\n",
        "\n",
        "        # Mostrar Top-K\n",
        "        print(f\"Resultados para {filename}:\")\n",
        "        for i, (n, p) in enumerate(zip(topk_names, topk_probs), 1):\n",
        "            print(f\"  {i}. {n:20s}  {p*100:5.2f}%\")\n",
        "        print(\"-\"*40)\n",
        "\n",
        "    print(\"Proceso de inferencia finalizado.\")"
      ],
      "metadata": {
        "id": "uqWZsgaVu8P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab: convertir un único WAV subido a Mel-spectrogram 16 kHz y guardar PNG\n",
        "# Requiere (ejecutar solo una vez si hace falta):\n",
        "!pip install -q librosa soundfile matplotlib tqdm\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "# Salida por defecto (una sola imagen)\n",
        "DST_ROOT = Path(\"/content/single_mel\")\n",
        "SAMPLE_RATE = 16000       # 16 kHz requerido\n",
        "N_MELS = 128              # número de bandas Mel\n",
        "N_FFT = 1024              # tamaño FFT\n",
        "HOP_LENGTH = 256\n",
        "FMIN = 0\n",
        "FMAX = None               # None -> sr/2\n",
        "FIG_DPI = 100             # resolución al guardar png\n",
        "SAVE_NPY = False          # si True guarda también .npy mel\n",
        "# ----------------------------\n",
        "\n",
        "def ensure_dir(path: Path):\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def wav_to_mel_db(y, sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, fmin=FMIN, fmax=FMAX):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length,\n",
        "                                         n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return mel_db\n",
        "\n",
        "def save_mel_png(mel_db, out_path: Path, dpi=FIG_DPI):\n",
        "    # Guarda el espectrograma mel_db como PNG sin ejes, fondo negro y margen cero.\n",
        "    # Ajustamos figura para que la resolución sea consistente.\n",
        "    h, w = mel_db.shape\n",
        "    plt.figure(figsize=(w / dpi, h / dpi), dpi=dpi)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(mel_db, aspect='auto', origin='lower', interpolation='nearest')\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "def process_single_wav_bytes(wav_bytes: bytes, out_dir: Path, filename_stem: str):\n",
        "    try:\n",
        "        # Guardar temporalmente para que librosa pueda abrirlo sin problemas\n",
        "        tmp_path = out_dir / (filename_stem + \"_tmp.wav\")\n",
        "        ensure_dir(out_dir)\n",
        "        with open(tmp_path, \"wb\") as f:\n",
        "            f.write(wav_bytes)\n",
        "\n",
        "        # Cargar y re-muestrear a SAMPLE_RATE (librosa.load mezcla a mono por defecto)\n",
        "        y, sr = librosa.load(str(tmp_path), sr=SAMPLE_RATE, mono=True)\n",
        "        if y.size == 0:\n",
        "            print(f\"Warning: archivo vacío {filename_stem}\")\n",
        "            tmp_path.unlink(missing_ok=True)\n",
        "            return False\n",
        "\n",
        "        mel_db = wav_to_mel_db(y, SAMPLE_RATE)\n",
        "        out_img_path = out_dir / (filename_stem + \".png\")\n",
        "        save_mel_png(mel_db, out_img_path)\n",
        "\n",
        "        if SAVE_NPY:\n",
        "            npy_path = out_dir / (filename_stem + \".npy\")\n",
        "            np.save(npy_path, mel_db.astype(np.float32))\n",
        "\n",
        "        # limpiar temporal\n",
        "        tmp_path.unlink(missing_ok=True)\n",
        "        print(f\"Guardado: {out_img_path}\")\n",
        "        return out_img_path, mel_db\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR procesando {filename_stem}: {e}\")\n",
        "        return False\n",
        "\n",
        "# ====== MAIN: pedir al usuario que suba un WAV ======\n",
        "print(\"Arrastra/sube un archivo WAV (o mp3/flac) ahora — solo un archivo será procesado:\")\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise SystemExit(\"No se subió ningún archivo. Ejecuta la celda nuevamente y sube un archivo WAV.\")\n",
        "\n",
        "# Tomar el primer archivo de audio subido válido\n",
        "wav_bytes = None\n",
        "wav_name = None\n",
        "for fname, b in uploaded.items():\n",
        "    if any(fname.lower().endswith(ext) for ext in ('.wav', '.flac', '.mp3', '.m4a', '.aac', '.ogg')):\n",
        "        wav_bytes = b\n",
        "        wav_name = fname\n",
        "        break\n",
        "\n",
        "if wav_bytes is None:\n",
        "    raise SystemExit(\"No se detectó un archivo de audio válido entre los archivos subidos.\")\n",
        "\n",
        "# Procesar\n",
        "ensure_dir(DST_ROOT)\n",
        "stem = Path(wav_name).stem\n",
        "res = process_single_wav_bytes(wav_bytes, DST_ROOT, stem)\n",
        "if not res:\n",
        "    raise SystemExit(\"Fallo en el procesamiento del archivo de audio.\")\n",
        "\n",
        "out_img_path, mel_db = res\n",
        "\n",
        "# Mostrar imagen resultante en el notebook y algunas estadísticas\n",
        "from IPython.display import display\n",
        "img = Image.open(out_img_path)\n",
        "display(img)\n",
        "\n",
        "print(\"\\nDetalles:\")\n",
        "print(\" - Archivo de audio:\", wav_name)\n",
        "print(\" - Output PNG:\", out_img_path)\n",
        "print(\" - Forma del mel (bands x frames):\", mel_db.shape)\n",
        "print(\" - Sample rate for processing:\", SAMPLE_RATE)\n",
        "if SAVE_NPY:\n",
        "    print(\" - También se guardó .npy con los datos MEL en la misma carpeta.\")\n",
        "\n",
        "print(\"\\nListo — tu espectrograma MEL (16 kHz) está en:\", DST_ROOT)\n"
      ],
      "metadata": {
        "id": "KVRa4u1xwyIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready: convertir todos los WAV en /content/dataset/... a espectrogramas MEL 16kHz\n",
        "# Salida: /content/dataset_mel/train|val|test/<clase>/<misma_name>.png\n",
        "# Requiere: librosa, matplotlib, soundfile, tqdm\n",
        "# Ejecuta solo una vez la instalación:\n",
        "!pip install -q librosa soundfile matplotlib tqdm\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "SRC_ROOT = Path(\"/content/dataset\")            # carpeta origen (ya la tienes)\n",
        "DST_ROOT = Path(\"/content/dataset_mel\")        # carpeta destino (nueva)\n",
        "SAMPLE_RATE = 16000                            # 16 kHz requerido\n",
        "N_MELS = 128                                   # número de bandas Mel\n",
        "N_FFT = 1024                                   # tamaño FFT\n",
        "HOP_LENGTH = 256\n",
        "FMIN = 0\n",
        "FMAX = None                                    # None -> sr/2\n",
        "FIG_DPI = 100                                  # resolución al guardar png\n",
        "SAVE_NPY = False                                # si True guarda también .npy mel (descomentar si quieres)\n",
        "# ----------------------------\n",
        "\n",
        "def ensure_dir(path: Path):\n",
        "    if not path.exists():\n",
        "        path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def wav_to_mel_db(y, sr, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP_LENGTH, fmin=FMIN, fmax=FMAX):\n",
        "    # Calcula mel spectrogram y lo pasa a escala dB (log)\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length,\n",
        "                                         n_mels=n_mels, fmin=fmin, fmax=fmax)\n",
        "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "    return mel_db\n",
        "\n",
        "def save_mel_png(mel_db, out_path: Path, dpi=FIG_DPI):\n",
        "    # Guarda el espectrograma mel_db como PNG sin ejes, fondo negro y margen cero.\n",
        "    plt.figure(figsize=(mel_db.shape[1] / dpi, mel_db.shape[0] / dpi), dpi=dpi)\n",
        "    plt.axis('off')\n",
        "    # mostrar con origin='lower' para que el eje mel crezca hacia arriba\n",
        "    plt.imshow(mel_db, aspect='auto', origin='lower', interpolation='nearest')\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.savefig(out_path, bbox_inches='tight', pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "def process_file(src_path: Path, dst_img_path: Path):\n",
        "    try:\n",
        "        # cargamos y re-muestreamos a SAMPLE_RATE\n",
        "        # librosa.load hace mezcla a mono por defecto (sr resamplea)\n",
        "        y, sr = librosa.load(str(src_path), sr=SAMPLE_RATE, mono=True)\n",
        "        if y.size == 0:\n",
        "            print(f\"Warning: archivo vacío {src_path}\")\n",
        "            return False\n",
        "\n",
        "        mel_db = wav_to_mel_db(y, SAMPLE_RATE)\n",
        "        ensure_dir(dst_img_path.parent)\n",
        "        save_mel_png(mel_db, dst_img_path)\n",
        "\n",
        "        if SAVE_NPY:\n",
        "            npy_path = dst_img_path.with_suffix('.npy')\n",
        "            np.save(npy_path, mel_db.astype(np.float32))\n",
        "\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR procesando {src_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "# ====== MAIN ======\n",
        "if not SRC_ROOT.exists():\n",
        "    raise SystemExit(f\"Directorio origen no existe: {SRC_ROOT}\")\n",
        "\n",
        "# Recrear estructura train/val/test y subcarpetas de clases en DST_ROOT\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "files_to_process = []\n",
        "\n",
        "for split in splits:\n",
        "    src_split = SRC_ROOT / split\n",
        "    if not src_split.exists():\n",
        "        # si alguna de las carpetas no existiera, lo notificamos pero seguimos\n",
        "        print(f\"Advertencia: {src_split} no existe. Se omitirá.\")\n",
        "        continue\n",
        "    for class_dir in src_split.iterdir():\n",
        "        if not class_dir.is_dir():\n",
        "            continue\n",
        "        # creamos carpeta destino correspondiente\n",
        "        dst_class_dir = DST_ROOT / split / class_dir.name\n",
        "        ensure_dir(dst_class_dir)\n",
        "        # recogemos archivos de audio dentro de esta carpeta\n",
        "        # aceptamos wav, wav1, wav2, flac, mp3 (librosa soporta varios)\n",
        "        for ext in (\"*.wav\", \"*.WAV\", \"*.flac\", \"*.FLAC\", \"*.mp3\", \"*.MP3\", \"*.m4a\", \"*.M4A\"):\n",
        "            for p in class_dir.glob(ext):\n",
        "                files_to_process.append((p, dst_class_dir / (p.stem + \".png\")))\n",
        "\n",
        "print(f\"Archivos a procesar: {len(files_to_process)}\")\n",
        "# Procesar con tqdm\n",
        "errors = 0\n",
        "for src_path, dst_img_path in tqdm(files_to_process):\n",
        "    ok = process_file(src_path, dst_img_path)\n",
        "    if not ok:\n",
        "        errors += 1\n",
        "\n",
        "print(\"=== FIN ===\")\n",
        "print(f\"Total archivos: {len(files_to_process)}  - Errores: {errors}\")\n",
        "print(f\"Espectrogramas guardados en: {DST_ROOT}\")\n",
        "\n",
        "# Opcional: listar algunas muestras guardadas\n",
        "sample_preview = list((DST_ROOT / \"train\").rglob(\"*.png\"))[:6]\n",
        "if sample_preview:\n",
        "    print(\"Algunas muestras (primeras 6) guardadas:\")\n",
        "    for p in sample_preview:\n",
        "        print(\" -\", p)\n",
        "else:\n",
        "    print(\"No se encontraron muestras en destino. Revisa rutas.\")\n"
      ],
      "metadata": {
        "id": "CMNAU-YJw454"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1️⃣ Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2️⃣ Rutas\n",
        "carpeta_origen = '/content/dataset_mel'\n",
        "ruta_salida = '/content/drive/MyDrive/dataset_mel.zip'  # Cambia el nombre o la ruta si quieres\n",
        "\n",
        "# 3️⃣ Comprimir la carpeta\n",
        "shutil.make_archive(base_name=ruta_salida.replace('.zip', ''), format='zip', root_dir=carpeta_origen)\n",
        "\n",
        "print(f\"✅ Carpeta comprimida y guardada en Drive: {ruta_salida}\")"
      ],
      "metadata": {
        "id": "eQZsbtAKw-nh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}